{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic mrjob usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mr_word_count.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mr_word_count.py\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        yield \"chars\", len(line)\n",
    "        yield \"words\", len(line.split())\n",
    "        yield \"lines\", 1\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_file.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_file.txt\n",
    "Hello cat people! \n",
    "\n",
    "All cats and friends of cats are welcome to ride the catamaran!\n",
    "\n",
    "Cats are friends to people in need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple way to run the job locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/mr_word_count.Jason.20160919.035730.154339\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/mr_word_count.Jason.20160919.035730.154339/output...\n",
      "\"chars\"\t82\n",
      "\"lines\"\t3\n",
      "\"words\"\t15\n",
      "Removing temp directory /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/mr_word_count.Jason.20160919.035730.154339...\n"
     ]
    }
   ],
   "source": [
    "!python mr_word_count.py my_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/mr_word_count.Jason.20160919.035731.612045\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/mr_word_count.Jason.20160919.035731.612045/output...\n",
      "\"chars\"\t82\n",
      "\"lines\"\t3\n",
      "\"words\"\t15\n",
      "Removing temp directory /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/mr_word_count.Jason.20160919.035731.612045...\n"
     ]
    }
   ],
   "source": [
    "!python mr_word_count.py -r local my_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No debugging messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"chars\"\t116\r\n",
      "\"lines\"\t5\r\n",
      "\"words\"\t22\r\n"
     ]
    }
   ],
   "source": [
    "!python mr_word_count.py -r local -q my_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OutStream' object has no attribute 'buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-2e143118b53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmr_word_count\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMRWordFrequencyCount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmr_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMRWordFrequencyCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'my_file.txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# with mr_job.make_runner() as runner:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/BlueOwl1/anaconda/lib/python3.5/site-packages/mrjob/job.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m \u001b[0mmrjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhelp\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMRJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmr_job_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/BlueOwl1/anaconda/lib/python3.5/site-packages/mrjob/launch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, script_path, args, from_cl)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OutStream' object has no attribute 'buffer'"
     ]
    }
   ],
   "source": [
    "# %%writefile test.py\n",
    "from mr_word_count import MRWordFrequencyCount\n",
    "\n",
    "mr_job = MRWordFrequencyCount(args=['my_file.txt'])\n",
    "\n",
    "# with mr_job.make_runner() as runner:\n",
    "#     runner.run() \n",
    "#     for line in runner.stream_output(): \n",
    "#         print(mr_job.parse_output_line(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chars', 82)\r\n",
      "('lines', 3)\r\n",
      "('words', 15)\r\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chars', 116)\n",
      "('lines', 5)\n",
      "('words', 22)\n"
     ]
    }
   ],
   "source": [
    "# Hacky way to make it work\n",
    "temp = !python test.py\n",
    "for t in temp:\n",
    "    print(eval(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multistep job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing top_word.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_word.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "\n",
    "class MRMostUsedWord(MRJob):\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_words,\n",
    "                   combiner=self.combiner_count_words,\n",
    "                   reducer=self.reducer_count_words),\n",
    "            MRStep(reducer=self.reducer_find_max_word)\n",
    "        ]\n",
    "\n",
    "    def mapper_get_words(self, _, line):\n",
    "        # yield each word in the line\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield (word.lower(), 1)\n",
    "\n",
    "    def combiner_count_words(self, word, counts):\n",
    "        # optimization: sum the words we've seen so far\n",
    "        yield (word, sum(counts))\n",
    "\n",
    "    def reducer_count_words(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is so we can easily use Python's max() function.\n",
    "        yield None, (sum(counts), word)\n",
    "\n",
    "    # discard the key; it is just None\n",
    "    def reducer_find_max_word(self, _, word_count_pairs):\n",
    "        # each item of word_count_pairs is (count, word),\n",
    "        # so yielding one results in key=counts, value=word\n",
    "        yield max(word_count_pairs)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRMostUsedWord.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 4, 4, 4, 4, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [1,2,3,4,5,6,7]\n",
    "temp[3:3] = [temp[3]]*5\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/top_word.Jason.20160918.220934.543803\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "Streaming final output from /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/top_word.Jason.20160918.220934.543803/output...\n",
      "2\t\"cats\"\n",
      "Removing temp directory /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/top_word.Jason.20160918.220934.543803...\n"
     ]
    }
   ],
   "source": [
    "!python top_word.py -r local my_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word count where we try to not use builtin abstractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(\"cat\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting word_count_no_abstractions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word_count_no_abstractions.py\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "class WordCount(MRJob):\n",
    "    \n",
    "    def steps(self):\n",
    "        return [\n",
    "                MRStep(mapper=self.mapper_emit_words,\n",
    "                       combiner=self.combiner_count_words,\n",
    "                       reducer=self.reducer_count_words),\n",
    "                MRStep(mapper=self.mapper_make_cap,\n",
    "                       reducer_init=self.reducer_init_for_status,\n",
    "                       reducer=self.reducer_find_max_word)\n",
    "                ]\n",
    "    \n",
    "    def mapper_emit_words(self, _, line):\n",
    "        self.increment_counter('stats', 'characters', len(line))\n",
    "        self.increment_counter('stats', 'lines', 1)\n",
    "        for word in WORD_RE.findall(line.lower()):\n",
    "            self.increment_counter('stats', 'words', 1)\n",
    "            yield (word, 1)\n",
    "            \n",
    "    def combiner_count_words(self, word, count):\n",
    "        yield (word, sum(count))\n",
    "        \n",
    "    def reducer_count_words(self, word, count):\n",
    "        yield (word, sum(count))\n",
    "    \n",
    "    \n",
    "    def mapper_make_cap(self, word, count):\n",
    "        yield None, (word.upper(), count)\n",
    "    \n",
    "    def reducer_init_for_status(self):\n",
    "        self.status = 0\n",
    "    \n",
    "    def reducer_find_max_word(self, _, word_count):\n",
    "        if self.status == 0:\n",
    "            self.set_status(type(word_count))\n",
    "            self.status = 1\n",
    "        yield max(word_count, key=lambda x: x[1])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    WordCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/word_count_no_abstractions.Jason.20160919.061619.467904\n",
      "Running step 1 of 2...\n",
      "Counters: 3\n",
      "\tstats\n",
      "\t\tcharacters=116\n",
      "\t\tlines=5\n",
      "\t\twords=22\n",
      "Counters: 3\n",
      "\tstats\n",
      "\t\tcharacters=116\n",
      "\t\tlines=5\n",
      "\t\twords=22\n",
      "Running step 2 of 2...\n",
      "Streaming final output from /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/word_count_no_abstractions.Jason.20160919.061619.467904/output...\n",
      "\"CATS\"\t3\n",
      "Removing temp directory /var/folders/sz/4k2bbjts7x5fmg9sn7kh6hlw0000gn/T/word_count_no_abstractions.Jason.20160919.061619.467904...\n"
     ]
    }
   ],
   "source": [
    "!python word_count_no_abstractions.py my_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a sample of the file\n",
    "!head -n 2000 data/anonymous-msweb.data.txt > data/anonymous-msweb.data.sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V,1034,1\r\n",
      "C,\"10398\",10398\r\n",
      "V,1036,1\r\n",
      "V,1040,1\r\n",
      "C,\"10399\",10399\r\n",
      "V,1008,1\r\n",
      "V,1052,1\r\n",
      "V,1018,1\r\n",
      "C,\"10400\",10400\r\n",
      "V,1004,1\r\n"
     ]
    }
   ],
   "source": [
    "# View a few instances of the file\n",
    "!tail -n 10 data/anonymous-msweb.data.sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting AtLeastKViews.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile AtLeastKViews.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.compat import jobconf_from_env\n",
    "\n",
    "class AtLeastKViews(MRJob):\n",
    "    \"\"\"\n",
    "    Given the Vlog dataset, returns all the pages that have over K views\n",
    "    along with the view count.\n",
    "    \n",
    "    usage: \n",
    "    $ python AtLeastKViews.py [--jobconf \"k=1000\"] [-q] <data>\n",
    "    \"\"\"\n",
    "    def steps(self):\n",
    "        \"\"\"\n",
    "        Defines a single step job\n",
    "        \"\"\"\n",
    "        mr_steps = [MRStep(mapper=self.mapper_filter_only_Vs,\n",
    "                           combiner=self.combiner_sum_sites,\n",
    "                           reducer_init=self.reducer_init,\n",
    "                           reducer=self.reducer_sum_and_filter_sites)]\n",
    "        return mr_steps\n",
    "    \n",
    "    def mapper_filter_only_Vs(self, _, lines):\n",
    "        if lines[0] == \"V\":\n",
    "            terms = lines.split(\",\")\n",
    "            yield(terms[1], 1)\n",
    "            \n",
    "    def combiner_sum_sites(self, site, count):\n",
    "        # Remember, the mapper returns a generator and the value\n",
    "        # is a generator as well.\n",
    "        yield(site, sum(count))\n",
    "        \n",
    "    def reducer_init(self):\n",
    "        # Good example on how to define arguments to use\n",
    "        self.greater_than = int(jobconf_from_env(\"k\", default=50))\n",
    "        \n",
    "    def reducer_sum_and_filter_sites(self, site, count):\n",
    "        site_count = sum(count)\n",
    "        if site_count >= self.greater_than:\n",
    "            yield(site, site_count)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    AtLeastKViews.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1001\"\t4451\r\n",
      "\"1003\"\t2968\r\n",
      "\"1004\"\t8463\r\n",
      "\"1008\"\t10836\r\n",
      "\"1009\"\t4628\r\n",
      "\"1017\"\t5108\r\n",
      "\"1018\"\t5330\r\n",
      "\"1020\"\t1087\r\n",
      "\"1025\"\t2123\r\n",
      "\"1026\"\t3220\r\n",
      "\"1030\"\t1115\r\n",
      "\"1032\"\t1446\r\n",
      "\"1034\"\t9383\r\n",
      "\"1035\"\t1791\r\n",
      "\"1037\"\t1160\r\n",
      "\"1038\"\t1110\r\n",
      "\"1040\"\t1506\r\n",
      "\"1041\"\t1500\r\n"
     ]
    }
   ],
   "source": [
    "!python AtLeastKViews.py --jobconf \"k=1000\" -q data/anonymous-msweb.data.txt"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
